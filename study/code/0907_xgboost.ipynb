{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T08:29:42.736350Z",
     "start_time": "2020-09-07T08:29:42.726291Z"
    }
   },
   "outputs": [],
   "source": [
    "# Xgboost\n",
    "'''\n",
    "XGBoost는 Gradient Boosting 알고리즘을 분산환경에서도 실행할 수 있도록\n",
    "구현해놓은 라이브러리이다\n",
    "XGBoost는 여러개의 Decision Tree를 조합해서 사용하는 ensemble 알고리즘이다\n",
    "\n",
    "boosting(부스팅)\n",
    "- 라운드가 지날수록 모델의 에러를 줄이는 과정\n",
    "- 어떤 모델이 유효한지, 적절한지를 찾아내는 과정\n",
    "- 약한 예측 모형들을 결합해 강한 예측 모형을 만드는 알고리즘\n",
    "- 무작위성이 없으며 강력한 사전 가지치기 사용\n",
    "\n",
    "결측치를 내부적으로 처리해준다\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T08:29:42.774752Z",
     "start_time": "2020-09-07T08:29:42.737710Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameter\n",
    "'''\n",
    "booster : 부스터 구조 선택\n",
    "- gbtree = Gradient  Boosted Decision trees\n",
    "- gblinear = Gradient Boosted linear\n",
    "- dart = Dropout Regression Trees\n",
    "\n",
    "n_estimators : 결정 트리의 개수\n",
    "n_jobs : 동시에 사용할 쓰레드 개수(default는 가능한 많이)\n",
    "num_feature : feature 차원의 숫자를 정해야 할 경우 사용 (default는 가능한 많이)\n",
    "num_boost_rounds : boosting 라운드를 결정한다\n",
    "                   랜덤하게 생성되는 모델이므로 적당히 큰 수가 좋다\n",
    "nrounds : 부스팅 반복 횟수\n",
    "\n",
    "colsample_bytree : 컬럼의 샘플링 비율\n",
    "subsample : 약한 모델이 학습에 사용하는 데이터 샘플링 비율\n",
    "\n",
    "eta : learning rate로 boosting step마다 weight를 줘서 부스팅 과정에\n",
    "      과적합(overfitting)이 일어나지 않도록 한다\n",
    "gamma : information gain에서 r로 표현한 값. 이 값이 커지면 트리 깊이가 줄어들어\n",
    "        보수적인 모델이 된다\n",
    "max_depth : 한 트리의 maximum depth. default는 6이고\n",
    "            이 경우 리프 노드의 개수는 최대 2^6개\n",
    "lambda(l2 reg-form) : l2 regularization form weight로\n",
    "                      숫자가 클수록 보수적인 모델이다\n",
    "alpha(l1 reg-form) : l1 regularization form weight로\n",
    "                     숫자가 클수록 보수적인 모델이다\n",
    "\n",
    "objective : 목적함수로 reg:linear, binary:logistic, count:poisson 등 다양하다\n",
    "eval_metric : 모델 평가 함수로 rmse, logloss, mae 등이 있다\n",
    "\n",
    "early_stopping_rounds : 특정 횟수를 지나도 모델이 개선되지 않을 때\n",
    "                        조기에 종료시킨다\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T08:29:47.013560Z",
     "start_time": "2020-09-07T08:29:42.776654Z"
    }
   },
   "outputs": [],
   "source": [
    "# example\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import os\n",
    "seed = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T08:29:48.230908Z",
     "start_time": "2020-09-07T08:29:47.014551Z"
    }
   },
   "outputs": [],
   "source": [
    "train = np.load('data/train.npy', allow_pickle = 'True')\n",
    "test = np.load('data/test.npy', allow_pickle = 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T08:29:48.247364Z",
     "start_time": "2020-09-07T08:29:48.232901Z"
    }
   },
   "outputs": [],
   "source": [
    "x = train[:,2:]\n",
    "x = np.reshape(x, (-1, 28, 28, 1))\n",
    "\n",
    "y = train[:,0]\n",
    "y = np.reshape(y, (-1,1))\n",
    "en = LabelEncoder()\n",
    "y = en.fit_transform(y)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T08:29:48.279254Z",
     "start_time": "2020-09-07T08:29:48.250353Z"
    }
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1, \n",
    "                                     zoom_range=[0.8,1.2],\n",
    "                                     shear_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T08:29:50.085582Z",
     "start_time": "2020-09-07T08:29:48.280251Z"
    }
   },
   "outputs": [],
   "source": [
    "x_total = x.copy()\n",
    "def augment(x):\n",
    "    aug_list = []\n",
    "    for i in range(x.shape[0]):\n",
    "        num_aug = 0\n",
    "        tmp = x[i]\n",
    "        tmp = tmp.reshape((1,) + tmp.shape)\n",
    "        for x_aug in image_generator.flow(tmp, batch_size = 1) :\n",
    "            if num_aug >= 1:\n",
    "                break\n",
    "            aug_list.append(x_aug[0])\n",
    "            num_aug += 1\n",
    "    aug_list = np.array(aug_list)\n",
    "    return aug_list\n",
    "\n",
    "n = 2\n",
    "for i in range(n):\n",
    "    arr = augment(x)\n",
    "    x_total = np.concatenate((x_total, arr), axis=0)\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "y_total = y.copy()\n",
    "for i in range(n):\n",
    "    arr = y.copy()\n",
    "    y_total = np.concatenate((y_total, arr), axis=0)\n",
    "\n",
    "x_total = np.reshape(x_total, (-1, 784))\n",
    "    \n",
    "print(x_total.shape)\n",
    "print(y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T08:29:52.142411Z",
     "start_time": "2020-09-07T08:29:50.088573Z"
    }
   },
   "outputs": [],
   "source": [
    "pca_x = x_total.copy()\n",
    "pca = PCA()\n",
    "pca.fit(pca_x)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "n = np.argmax(cumsum >= 0.99) + 1\n",
    "print(n)\n",
    "\n",
    "def pca_data(data, n):\n",
    "    pca = PCA(n_components=n)\n",
    "    x = data.copy()\n",
    "    w = pca.fit_transform(x)\n",
    "    return w\n",
    "\n",
    "x_pca = pca_data(x_total, n+4)\n",
    "print(x_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T08:29:52.148130Z",
     "start_time": "2020-09-07T08:29:52.144407Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#x_train, x_val, y_train, y_val = train_test_split(x_pca, y_total,\n",
    "#                                                  test_size=0.2, shuffle=True)\n",
    "\n",
    "#print(x_train.shape)\n",
    "#print(x_val.shape)\n",
    "#print(y_train.shape)\n",
    "#print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T08:30:52.957626Z",
     "start_time": "2020-09-07T08:30:52.953639Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(booster='gbtree', objective='multi:softmax')\n",
    "xgb_params = {'max_depth':[3,5,7,9], 'n_estimators':[50,100,150,200],\n",
    "              'learning_rate':[0.01,0.05,0.1,0.15,0.2],\n",
    "              'subsample':[0.6,0.8,1.0],'min_child_weight':[1,5,10],\n",
    "              'gamma':[0.5,1,1.5,2], 'max_delta_step':[1,3,5,7,9],\n",
    "              'reg_alpha':[1e-5,1e-2,0.1,1,100]}\n",
    "search = GridSearchCV(xgb, xgb_params, cv=5)\n",
    "best_xgb = search.fit(x_pca, y_total, verbose=1)\n",
    "best_params = search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T08:30:52.983563Z",
     "start_time": "2020-09-07T08:30:52.960149Z"
    }
   },
   "outputs": [],
   "source": [
    "print(best_xgb)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T08:31:36.846482Z",
     "start_time": "2020-09-07T08:31:33.672153Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test = test[:,1:]\n",
    "x_test = np.reshape(x_test, (-1, 784))\n",
    "test_pca = pca_data(x_test, n+4)\n",
    "print(test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T08:30:53.015455Z",
     "start_time": "2020-09-07T08:30:52.996521Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = best_xgb.predict(test_pca)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T08:30:53.040379Z",
     "start_time": "2020-09-07T08:30:53.030407Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission = pd.read_csv('data/submission.csv')\n",
    "#submission['digit'] = np.argmax(best_model.predict(x_test), axis=1)\n",
    "#submission.to_csv('data/submission_xgboost(0907).csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
