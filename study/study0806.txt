- 모델의 성능 지표는 'accuracy'가 높아지는 것에 보다 'loss'가 최소가 되는 것에 중점을 두어야 한다. 모델의 궁극적인 목표는  'loss'가 최소가 되는 최적의 weight를 구하는 것이기 때문이다. 'loss'는 label값과 모델이 예측한 값의 차이이다.

- 정제된 데이터에 쓸데없는 라벨인코더, 카테고리컬 함수 등을 사용할 필요없다.
- metrics에 2개 이상의 값을 넣는 이유가 있어야 한다.
- 코드는 이유가 있어야 하며, 설명 가능한 것만 사용해야 한다.

- Dense의 default activation은 linear다.

- 이진분류 
-> output layer의 activation = sigmoid
-> loss = binary_crossentropy
-> metrics = accuracy

- 다중분류
-> output layer의 activation = softmax
-> loss = categorical_crossentropy
-> metrics = accuracy

- 회귀문제
-> output layer의 activation = default(linear)
-> loss = mse or mae
-> metrics = mae or mse

- model.evaluate(x, y)
-> 변수를 하나로 받으면 리스트로 loss값과 metrics값이 들어온다.
-> 리스트에 해당하는 값들을 각각 변수로 받을 수 있다.

- Dense의 model.summary()
-> y = wx + b 라는 기본식을 바탕으로 구동한다.
-> w는 weight로 다음 노드로 연결될 때 계산된다.
-> b는 bias로 각 layer마다 존재한다.
-> 따라서, 각 Dense마다 계산해야 하는 Parameters는 (input 차원 + bias) * (노드의 수)이다.

- Decision tree / Random forest / xgboost / lightGBM
-> tree 기반의 모델이다.
-> feature importance를 알 수 있다.

- PCA
-> feature(=column)의 차원을 줄여준다.
-> 계산해야 할 양이 줄어들어 모델의 컴퓨팅 시간을 줄여준다.
-> 그렇다고 모델의 성능이 줄어들지는 않는다.

- 함수형 모델을 구사할 줄 알아야한다.
- keras와 머신러닝을 연계해서 여러 하이퍼파라미터 조합을 한번에 돌릴 줄 알아야한다.
- 모델을 돌릴 때, earlystopping과 좋은 가중치 모델을 저장하는 코드를 사용해야 한다.