{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T06:11:49.236789Z",
     "start_time": "2020-08-10T06:11:49.232788Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D     # Convolution 2D(가로 * 세로) : 이미지 자르는 것\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T06:15:18.178840Z",
     "start_time": "2020-08-10T06:15:18.122421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 9, 9, 10)          130       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 7)           637       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 5)           145       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 5)           105       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 5)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 45)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 46        \n",
      "=================================================================\n",
      "Total params: 1,063\n",
      "Trainable params: 1,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # 이미지를 가로, 세로 2, 2로 자르겠다.  \n",
    "model.add(Conv2D(10, (2, 2), input_shape = (10, 10, 3)))                  # (N, 9, 9, 10)            \n",
    "model.add(Conv2D(7, (3, 3)))                                              # (N, 7, 7, 7)\n",
    "model.add(Conv2D(5, (2, 2), padding = 'same'))                            # (N, 7, 7, 5)\n",
    "model.add(Conv2D(5, (2, 2)))                                              # (N, 6, 6, 5)\n",
    "model.add(MaxPooling2D(pool_size = 2))                                    # (N, 3, 3, 5)\n",
    "model.add(Flatten())                                                      # (N, 45)      : 2차원\n",
    "model.add(Dense(1))                                                       # (N, 1)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Conv2D( 10,     (2, 2),     input_shape = (   10,    10,      1  ))\n",
    "       filter  kernal_size \n",
    "               자르는 size  x = ( batch_size, heigth, width, channel )  4차원\n",
    "                                 행(장수)     세로    가로     색깔   = 1 (흑백), 3(컬러)\n",
    "                                                              색깔끼리 나눠준다.\n",
    "# CNN_Output_Size\n",
    " : [(N - F + 2*padding_size) / stride] + 1 \n",
    " :이 사이즈의 그림이 이전 filter 수많큼 생성된다.\n",
    "                                                                         layer의 node수를 통해 data증폭\n",
    " ex) Conv2D(10, (3, 3), input_shape = (10, 10, 1)) => (None, 8, 8, 10) : (8 * 8) 이 10장 생성된다. (증폭)\n",
    "     Conv2D( 7, (4, 4))                            => (None, 5, 5,  7) : (5 * 5) 이  7장 생성된다. (증폭)\n",
    "     \n",
    "# Conv2D만 사용하여 layer구성시 문제점\n",
    " : filter로 잘려져 중복된 부분이 훈련이 더 많이 된다. -> side는  훈련 1번             =>  상대적인 데이터 손실\n",
    "                                                   -> 중첩부분 훈련 2번 -> 값이 치중됨\n",
    "# padding\n",
    " : side를 '0'으로 채워 side data도 동일하게 훈련될 수 있도록 해준다. \n",
    "  -> 홀수로 채울시 padding을 입히는 위치는 머신이 정한다.                                                 \n",
    "  = 'same' : kernal_size와 상관없이 input_shape와 동일한 shape로 전달해준다.\n",
    "  = 'valid' : default, (유효한 영역만 출력, 따라서 출력 이미지 사이즈는 입력 사이즈보다 작다)\n",
    "\n",
    "# strides\n",
    " : 필터의 이동 간격 \n",
    " : 가로, 세로 따로 지정 가능 => strides = (2,1) : 세로 2칸, 가로 1칸 (),[] 둘다 가능\n",
    " : 값이 커지면 data_size가 작아짐\n",
    " : default = 1 \n",
    "\n",
    "# MaxPooling\n",
    " : 필요없는 쓰레기 값을 버리고 중요부분(가장 큰 값)만 가져온다.\n",
    " : 학습 parameter가 없다.\n",
    " ex) 4 * 4 image\n",
    "     0  1  5  4        (2 * 2)\n",
    "     0 15 27 26    =>  15  27\n",
    "     0  4  7  8        5   13\n",
    "     0  5  6 13\n",
    " \n",
    " : heigth(width) / pool_size = MaxPooling (나누고 난 후의 소수점은 버린다.)\n",
    "\n",
    "# CNN_parameter\n",
    " :  ( channel * kernal_size  * filter ) + ( bias * filter)\n",
    "   = ( input_dim * kernal_size +  1 ) * output\n",
    " ex) (     1     *  (2 * 2)    +  1 ) *   10  \n",
    "\n",
    "http://aikorea.org/cs231n/convolutional-networks/ 참고\n",
    "-> stride는 output의 크기에만 영향을 미치고 parameter 수에는 영향을 미치지 않는다.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
